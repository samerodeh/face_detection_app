{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYBAF0MyRurr",
        "outputId": "46a2fdaf-ba29-46a1-aa42-d4a7bd7673d5"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'matplotlib' has no attribute 'style'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdark_background\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# imports\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\samer\\Desktop\\code\\projects\\face_detection_app\\.venv\\lib\\site-packages\\matplotlib\\_api\\__init__.py:218\u001b[0m, in \u001b[0;36mcaching_module_getattr.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name]\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance)\n\u001b[1;32m--> 218\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'style'"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib as plt\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "\n",
        "# imports\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import insightface\n",
        "from insightface.app import FaceAnalysis\n",
        "from mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "# extra imports\n",
        "\n",
        "import psycopg2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdVa0PzQQk7G",
        "outputId": "7a732d9f-bad5-4bb1-a671-5005bcb74f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ],
      "source": [
        "# load models\n",
        "\n",
        "app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
        "app.prepare(ctx_id=0) # load arcface/insight  and detects faces, so no need for mtcnn\n",
        "\n",
        "\n",
        "#detector = MTCNN() # detect faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6oR4VwzsIYJ",
        "outputId": "326b2b02-5b86-4cc0-c585-b5f9e4f2ea4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Connected to Railway PostgreSQL\n"
          ]
        }
      ],
      "source": [
        "# # railway connect\n",
        "\n",
        "# db_info = {\n",
        "#     \"host\": \"hopper.proxy.rlwy.net\",\n",
        "#     \"port\": 55475,\n",
        "#     \"dbname\": \"railway\",\n",
        "#     \"user\": \"postgres\",\n",
        "#     \"password\": \"syDhOVUIPvVxDdAlEztnmJdpvMZqxPUt\"\n",
        "# }\n",
        "\n",
        "# try:\n",
        "#     conn = psycopg2.connect(**db_info)\n",
        "#     cursor = conn.cursor()\n",
        "#     print(\"✅ Connected to Railway PostgreSQL\")\n",
        "# except Exception as e:\n",
        "#     print(\"❌ Connection failed:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI_d2pkpXt1A"
      },
      "outputs": [],
      "source": [
        "# postgres login\n",
        "\n",
        "db_info = {\n",
        "    \"host\": \"localhost\",\n",
        "    \"port\": \"5432\",\n",
        "    \"dbname\": \"face_embeddings\",\n",
        "    \"user\": \"postgres\",\n",
        "    \"password\": \"Ottawa2006!?\"\n",
        "}\n",
        "\n",
        "# create table\n",
        "\n",
        "create_table_sql = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS embeddings (\n",
        "    id SERIAL PRIMARY KEY,\n",
        "    person_name VARCHAR(100),\n",
        "    embedding FLOAT8[]  -- Stores the face embedding as an array\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    conn = psycopg2.connect(**db_info)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(create_table_sql)\n",
        "    conn.commit()\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "    print(\"✅ Table 'embeddings' created successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Error:\", e)\n",
        "\n",
        "\n",
        "# insert embeddings\n",
        "\n",
        "def insert_embedding(name, embedding):\n",
        "    conn = psycopg2.connect(**db_info)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\n",
        "        \"INSERT INTO embeddings (person_name, embedding) VALUES (%s, %s)\",\n",
        "        (name, embedding.tolist())\n",
        "    )\n",
        "    conn.commit()\n",
        "    cursor.close()\n",
        "    conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-P2LwDoTpJr"
      },
      "outputs": [],
      "source": [
        "def get_embedding(image_path):\n",
        "    img = np.array(Image.open(image_path).convert('RGB'))\n",
        "    faces = app.get(img)\n",
        "    if not faces:\n",
        "        print(f\"❌ No face detected in {image_path}\")\n",
        "        return None\n",
        "    return faces[0].embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS7Xyfju1SVy",
        "outputId": "c9131b51-0b11-4914-fd86-c461949997d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Embedding inserted successfully for: person1\n",
            "✅ Embedding inserted successfully for: person2\n"
          ]
        }
      ],
      "source": [
        "# insert embeddings as JSON\n",
        "def insert_embedding(person_name, embedding, db_info):\n",
        "    try:\n",
        "        conn = psycopg2.connect(**db_info)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Convert numpy array to JSON string\n",
        "        embedding_json = json.dumps(embedding.tolist())\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO face_embeddingsss (person_name, embeddings)\n",
        "            VALUES (%s, %s);\n",
        "        \"\"\", (person_name, embedding_json))\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "        conn.close()\n",
        "        print(\"✅ Embedding inserted successfully for:\", person_name)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Failed to insert embedding:\", e)\n",
        "\n",
        "# Usage\n",
        "insert_embedding(\"person1\", get_embedding(\"person1.webp\"), db_info)\n",
        "insert_embedding(\"person2\", get_embedding(\"person2.webp\"), db_info)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfQDitagT99N",
        "outputId": "1faa1695-9479-451d-a8b8-f42fa7966125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity: 0.081\n",
            "❌ Different people\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return dot(a, b) / (norm(a) * norm(b))\n",
        "\n",
        "face1_emb = get_embedding(file1)\n",
        "face2_emb = get_embedding(file2)\n",
        "\n",
        "if face1_emb is None or face2_emb is None:\n",
        "    print(\"❌ One or both images couldn't be read or no face detected.\")\n",
        "else:\n",
        "    similarity = cosine_similarity(face1_emb, face2_emb)\n",
        "    print(f\"Similarity: {similarity:.3f}\")\n",
        "    if similarity > 0.6:\n",
        "        print(\"✅ Same person\")\n",
        "    else:\n",
        "        print(\"❌ Different people\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01nzjgGPZsdN"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# face1 = crop_face('person1.webp')\n",
        "# face2 = crop_face('person2.webp')\n",
        "\n",
        "# if face1 is not None and face2 is not None:\n",
        "#     plt.figure(figsize=(6,3))\n",
        "#     plt.subplot(1,2,1)\n",
        "#     plt.imshow(face1)\n",
        "#     plt.title(\"person1\")\n",
        "\n",
        "#     plt.subplot(1,2,2)\n",
        "#     plt.imshow(face2)\n",
        "#     plt.title(\"person2\")\n",
        "\n",
        "#     plt.show()\n",
        "# else:\n",
        "#     print(\"❌ Failed to detect one or both faces.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
